{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goris/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_mp = pd.read_json(path_or_buf=\"file://localhost/Users/goris/nasa_nea/mpcorb_extended.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_nea = pd.read_json(path_or_buf=\"file://localhost/Users/goris/nasa_nea/nea_extended.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_mp_dups = pd.concat([df_mp, df_nea])\n",
    "\n",
    "# Dropping duplicates based on columns that are highly probable to have unique values per-row\n",
    "df_mp_pure = df_mp_dups.drop_duplicates(subset=['Peri', 'n'], keep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pha = df_nea[df_nea['PHA_flag'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_nea_pure = df_nea[df_nea['PHA_flag'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Set Count = 699486\n",
      "NEA Set Count = 12418\n",
      "PHA Set Count = 1679\n"
     ]
    }
   ],
   "source": [
    "print 'Master Set Count =', len(df_mp_pure.index)\n",
    "print 'NEA Set Count =', len(df_nea_pure.index)\n",
    "print 'PHA Set Count =', len(df_pha.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goris/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/goris/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/goris/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Adding Labels to the data\n",
    "df_mp_pure['Label'] = 2\n",
    "df_nea_pure['Label'] = 1\n",
    "df_pha['Label'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_joined = pd.concat([df_mp_pure, df_nea_pure, df_pha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aphelion_dist                         float64\n",
       "Critical_list_numbered_object_flag    float64\n",
       "Epoch                                 float64\n",
       "G                                     float64\n",
       "H                                     float64\n",
       "M                                     float64\n",
       "Node                                  float64\n",
       "Num_obs                               float64\n",
       "Num_opps                                int64\n",
       "One_km_NEO_flag                       float64\n",
       "One_opposition_object_flag            float64\n",
       "Orbital_period                        float64\n",
       "Peri                                  float64\n",
       "Perihelion_dist                       float64\n",
       "Semilatus_rectum                      float64\n",
       "Synodic_period                        float64\n",
       "Tp                                    float64\n",
       "a                                     float64\n",
       "e                                     float64\n",
       "i                                     float64\n",
       "n                                     float64\n",
       "rms                                   float64\n",
       "Label                                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deleting unrelevant features from the dataset\n",
    "df_joined = df_joined.copy().drop(['Hex_flags', 'Last_obs', 'Name', 'Number','Arc_years','Other_desigs',\n",
    "                            'Perturbers', 'Computer','Perturbers_2', 'Principal_desig', 'Ref', 'U', 'Arc_length'],axis=1)       \n",
    "                \n",
    "# df_joined = df_joined.copy().drop(['Num_obs', 'G',\n",
    "#                                   'Critical_list_numbered_object_flag',  'Node', 'Peri', 'NEO_flag', \n",
    "#                                   'Num_opps', 'One_km_NEO_flag', 'One_opposition_object_flag', 'Orbital_period',\n",
    "#                                   'PHA_flag', 'Semilatus_rectum', 'Synodic_period', 'rms',  'Tp','H'],\n",
    "#                           axis=1)\n",
    "\n",
    "df_joined = df_joined.copy().drop([ 'NEO_flag','PHA_flag'],\n",
    "                          axis=1)\n",
    "\n",
    "#substitute null values with 0s\n",
    "df_joined = df_joined.fillna(0.0)\n",
    "df_joined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Aphelion_dist', u'Critical_list_numbered_object_flag', u'Epoch', u'G',\n",
       "       u'H', u'M', u'Node', u'Num_obs', u'Num_opps', u'One_km_NEO_flag',\n",
       "       u'One_opposition_object_flag', u'Orbital_period', u'Peri',\n",
       "       u'Perihelion_dist', u'Semilatus_rectum', u'Synodic_period', u'Tp', u'a',\n",
       "       u'e', u'i', u'n', u'rms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the Label column as a Series from the master set\n",
    "sr_label = df_joined['Label']\n",
    "\n",
    "# Drop the Label column from the master data set\n",
    "df_joined = df_joined.drop('Label', axis=1)\n",
    "\n",
    "df_joined.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make train and test sets\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(df_joined, sr_label, test_size=.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(535187, 22)\n",
      "(178396, 22)\n",
      "(535187,)\n",
      "(178396,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# clf = svm.SVC(kernel='linear', C=1)\n",
    "# scores = cross_validation.cross_val_score(clf, X_train, y_train, cv=3, scoring=\"f1_weighted\")\n",
    "# fitted = clf.fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)\n",
    "# print scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goris/anaconda/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis --- Confusion matrix, without normalization\n",
      "[[   234    155     22]\n",
      " [   731   2109    285]\n",
      " [   136    194 174530]]\n",
      "Linear Discriminant Analysis --- Normalized confusion matrix\n",
      "[[  5.69e-01   3.77e-01   5.35e-02]\n",
      " [  2.34e-01   6.75e-01   9.12e-02]\n",
      " [  7.78e-04   1.11e-03   9.98e-01]]\n"
     ]
    }
   ],
   "source": [
    "#-----  LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train, y_train)\n",
    "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
    "                           solver='svd', store_covariance=False, tol=0.0001)\n",
    "y_pred = clf.predict(X_test)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Linear Discriminant Analysis --- Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "#plt.figure()\n",
    "#plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Linear Discriminant Analysis --- Normalized confusion matrix')\n",
    "print(cm_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear DiscriminantAnalysis Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99146281306755757"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Linear DiscriminantAnalysis Score')\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-----  LogisticRegression\n",
    "\n",
    "lr = linear_model.LogisticRegression(penalty='l1',dual=False,max_iter =100 )\n",
    "lr.fit(X_train,y_train)\n",
    "lr.score(X_test,y_test)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99584631942420232"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Logistic Regression Score')\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression --- Confusion matrix, without normalization\n",
      "[[    23    386      2]\n",
      " [    14   2810    301]\n",
      " [     0     38 174822]]\n",
      "Logistic Regression --- Normalized confusion matrix\n",
      "[[  5.60e-02   9.39e-01   4.87e-03]\n",
      " [  4.48e-03   8.99e-01   9.63e-02]\n",
      " [  0.00e+00   2.17e-04   1.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Logistic Regression --- Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "#plt.figure()\n",
    "#plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Logistic Regression --- Normalized confusion matrix')\n",
    "print(cm_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest Classifier Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99849211865736898"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----  Random Forest Classifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "print('Random FOrest Classifier Score')\n",
    "rfc.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random FOrest Classifier --- Confusion matrix, without normalization\n",
      "[[   189    222      0]\n",
      " [    46   3078      1]\n",
      " [     0      0 174860]]\n",
      "Random FOrest Classifier --- Normalized confusion matrix\n",
      "[[  4.60e-01   5.40e-01   0.00e+00]\n",
      " [  1.47e-02   9.85e-01   3.20e-04]\n",
      " [  0.00e+00   0.00e+00   1.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Random FOrest Classifier --- Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "#plt.figure()\n",
    "#plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Random FOrest Classifier --- Normalized confusion matrix')\n",
    "print(cm_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # df_pha_test = df_pha.copy().drop(['Hex_flags', 'Last_obs', 'Name', 'Number','Arc_years','Other_desigs',\n",
    "# #                             'Perturbers', 'Computer','Perturbers_2', 'Principal_desig', 'Ref', 'U',\n",
    "# #                                   'Arc_length', 'Label','PHA_flag'],\n",
    "# #                           axis=1).fillna(0.0)\n",
    "# df_pha_test = df_pha.copy().drop(['Hex_flags', 'Last_obs', 'Name', 'Number','Arc_years','Other_desigs',\n",
    "#                             'Perturbers', 'Computer','Perturbers_2', 'Principal_desig', 'Ref', 'U',\n",
    "#                                   'Arc_length', 'Label'],\n",
    "#                           axis=1).fillna(0.0)\n",
    "# # df_pha_test = df_pha.copy().drop(['Aphelion_dist', 'H', 'Perihelion_dist', 'Num_obs', 'Epoch', 'G',\n",
    "# #                                   'Critical_list_numbered_object_flag', 'M', 'Node', 'Peri', 'NEO_flag', \n",
    "# #                                   'Num_opps', 'One_km_NEO_flag', 'One_opposition_object_flag', 'Orbital_period',\n",
    "# #                                   'PHA_flag', 'Semilatus_rectum', 'Synodic_period', 'rms', 'n', 'e', 'Tp', 'a'],\n",
    "# #                           axis=1)\n",
    "# clf.score(df_pha_test.head(500), np.zeros((500,), dtype=np.int))\n",
    "# #clf.predict(df_pha_test.head(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # df_nea_test = df_nea_pure.copy().drop(['Hex_flags', 'Last_obs', 'Name', 'Number','Arc_years','Other_desigs',\n",
    "# #                             'Perturbers', 'Computer','Perturbers_2', 'Principal_desig', 'Ref', 'U',\n",
    "# #                                   'Arc_length', 'Label','PHA_flag'],\n",
    "# #                           axis=1).fillna(0.0)\n",
    "# df_nea_test = df_nea_pure.copy().drop(['Hex_flags', 'Last_obs', 'Name', 'Number','Arc_years','Other_desigs',\n",
    "#                             'Perturbers', 'Computer','Perturbers_2', 'Principal_desig', 'Ref', 'U',\n",
    "#                                   'Arc_length', 'Label'],\n",
    "#                           axis=1).fillna(0.0)\n",
    "# # df_nea_test = df_nea_pure.copy().drop(['Aphelion_dist', 'H', 'Perihelion_dist', 'Num_obs', 'Epoch', 'G',\n",
    "# #                                   'Critical_list_numbered_object_flag', 'M', 'Node', 'Peri', 'NEO_flag', \n",
    "# #                                   'Num_opps', 'One_km_NEO_flag', 'One_opposition_object_flag', 'Orbital_period',\n",
    "# #                                   'PHA_flag', 'Semilatus_rectum', 'Synodic_period', 'rms', 'n', 'e', 'Tp', 'a'],\n",
    "# #                           axis=1)\n",
    "# clf.score(df_nea_test.head(500), np.ones((500,), dtype=np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # df_mp_test = df_mp_pure.copy().drop(['Hex_flags', 'Last_obs', 'Name', 'Number','Arc_years','Other_desigs',\n",
    "# #                             'Perturbers', 'Computer','Perturbers_2', 'Principal_desig', 'Ref', 'U',\n",
    "# #                                   'Arc_length', 'Label', 'PHA_flag'],\n",
    "# #                           axis=1).fillna(0.0)\n",
    "# df_mp_test = df_mp_pure.copy().drop(['Hex_flags', 'Last_obs', 'Name', 'Number','Arc_years','Other_desigs',\n",
    "#                             'Perturbers', 'Computer','Perturbers_2', 'Principal_desig', 'Ref', 'U',\n",
    "#                                   'Arc_length', 'Label', 'PHA_flag'],\n",
    "#                           axis=1).fillna(0.0)\n",
    "# # df_mp_test = df_mp_pure.copy().drop(['Aphelion_dist', 'H', 'Perihelion_dist', 'Num_obs', 'Epoch', 'G',\n",
    "# #                                   'Critical_list_numbered_object_flag', 'M', 'Node', 'Peri', 'NEO_flag', \n",
    "# #                                   'Num_opps', 'One_km_NEO_flag', 'One_opposition_object_flag', 'Orbital_period',\n",
    "# #                                   'PHA_flag', 'Semilatus_rectum', 'Synodic_period', 'rms', 'n', 'e', 'Tp', 'a'],\n",
    "# #                           axis=1)\n",
    "# arr = np.full((500, 1), 2, dtype=np.int)\n",
    "# clf.score(df_mp_test.head(500), arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
